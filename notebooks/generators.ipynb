{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57050311",
   "metadata": {},
   "source": [
    "This notebook is a collection of code snipptes that can be used for text generation and embedding generation using the OpenAI API or the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f47ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "gclient = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "oclient = OpenAI(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ea141",
   "metadata": {},
   "source": [
    "These are ways to use Generator objects, either using the OpenAI API or the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665cf284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings! I am a large language model, trained by Google.\n",
      "Hello! I am an AI language model created by OpenAI. How may I assist thee today?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hi, who art thou?\"\n",
    "\n",
    "# Gemini API\n",
    "response1 = gclient.models.generate_content(model=\"gemini-2.5-flash\",contents=prompt)\n",
    "print(response1.text)\n",
    "# OpenAI API\n",
    "response2 = oclient.responses.create(model=\"gpt-4.1-nano\",input=\"Hi, who art thou?\")\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51a2b0",
   "metadata": {},
   "source": [
    "These are ways to make sentence embeddings, either using the OpenAI API or the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e63cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "# Using OpenAI\n",
    "response = oclient.embeddings.create(\n",
    "    input=\"What is the meaning of life?\",\n",
    "    model=\"text-embedding-3-small\")\n",
    "\n",
    "emb = response.data[0].embedding\n",
    "print(len(emb)) # print the dimension of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9957a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "# Gemini API\n",
    "result = gclient.models.embed_content(\n",
    "        model=\"gemini-embedding-exp-03-07\",\n",
    "        contents=\"What is the meaning of life?\",\n",
    "        config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")) # https://ai.google.dev/gemini-api/docs/embeddings\n",
    "\n",
    "embs = result.embeddings[0].values\n",
    "print(len(embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847eef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
